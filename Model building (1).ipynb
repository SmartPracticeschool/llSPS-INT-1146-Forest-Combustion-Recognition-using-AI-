{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#importing model building libraries\n",
    "import os\n",
    "os.chdir(\"C:/Users/HAI LENOVO/Desktop/remote intenship 2020/fotrst\")\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize the model\n",
    "model=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Convolution Layer\n",
    "model.add(Convolution2D(32,(3,3),input_shape=(64,64,3),activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Pooling Layer\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Flattening Layer\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=120, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Hidden Layer\n",
    "model.add(Dense(init=\"uniform\",activation=\"relu\",output_dim=120))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Add Output layer\n",
    "model.add(Dense(init=\"uniform\",activation=\"sigmoid\",output_dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(Dense(init=\"uniform\",activation=\"sigmoid\",output_dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 322 images belonging to 2 classes.\n",
      "Found 127 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train = train_datagen.flow_from_directory('Dataset/trainset',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                     class_mode = 'binary')\n",
    "x_test = test_datagen.flow_from_directory('Dataset/testset',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Fire': 0, 'Nofire': 1}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1f4dfab6c8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.preprocessing.image.DirectoryIterator at 0x1f4deff188>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=25, validation_data=<keras.pre..., steps_per_epoch=7, validation_steps=63)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "7/7 [==============================] - 82s 12s/step - loss: 0.1181 - accuracy: 0.9643 - val_loss: 4.4625 - val_accuracy: 0.0635\n",
      "Epoch 2/25\n",
      "7/7 [==============================] - 80s 11s/step - loss: 0.0871 - accuracy: 0.9485 - val_loss: 6.2938 - val_accuracy: 0.0230\n",
      "Epoch 3/25\n",
      "7/7 [==============================] - 71s 10s/step - loss: 0.1114 - accuracy: 0.9691 - val_loss: 5.7962 - val_accuracy: 0.0235\n",
      "Epoch 4/25\n",
      "7/7 [==============================] - 67s 10s/step - loss: 0.0718 - accuracy: 0.9821 - val_loss: 6.4402 - val_accuracy: 0.0240\n",
      "Epoch 5/25\n",
      "7/7 [==============================] - 1460s 209s/step - loss: 0.0636 - accuracy: 0.9742 - val_loss: 6.1749 - val_accuracy: 0.0075\n",
      "Epoch 6/25\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.0234 - accuracy: 0.9948 - val_loss: 5.4224 - val_accuracy: 0.0240\n",
      "Epoch 7/25\n",
      "7/7 [==============================] - 28s 4s/step - loss: 0.0532 - accuracy: 0.9794 - val_loss: 6.5247 - val_accuracy: 0.0315\n",
      "Epoch 8/25\n",
      "7/7 [==============================] - 316s 45s/step - loss: 0.0890 - accuracy: 0.9794 - val_loss: 6.3194 - val_accuracy: 0.0155\n",
      "Epoch 9/25\n",
      "7/7 [==============================] - 24s 3s/step - loss: 0.0602 - accuracy: 0.9821 - val_loss: 7.4804 - val_accuracy: 0.0240\n",
      "Epoch 10/25\n",
      "7/7 [==============================] - 38s 5s/step - loss: 0.0510 - accuracy: 0.9777 - val_loss: 7.2598 - val_accuracy: 0.0075\n",
      "Epoch 11/25\n",
      "7/7 [==============================] - 35s 5s/step - loss: 0.0521 - accuracy: 0.9794 - val_loss: 6.7242 - val_accuracy: 0.0325\n",
      "Epoch 12/25\n",
      "7/7 [==============================] - 30s 4s/step - loss: 0.0515 - accuracy: 0.9845 - val_loss: 7.7870 - val_accuracy: 0.0080\n",
      "Epoch 13/25\n",
      "7/7 [==============================] - 33s 5s/step - loss: 0.0389 - accuracy: 0.9821 - val_loss: 7.7503 - val_accuracy: 0.0235\n",
      "Epoch 14/25\n",
      "7/7 [==============================] - 755s 108s/step - loss: 0.0424 - accuracy: 0.9821 - val_loss: 7.2514 - val_accuracy: 0.0240\n",
      "Epoch 15/25\n",
      "7/7 [==============================] - 31s 4s/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 10.5119 - val_accuracy: 0.0075\n",
      "Epoch 16/25\n",
      "7/7 [==============================] - 27s 4s/step - loss: 0.0512 - accuracy: 0.9845 - val_loss: 8.5299 - val_accuracy: 0.0235\n",
      "Epoch 17/25\n",
      "7/7 [==============================] - 23s 3s/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 9.9355 - val_accuracy: 0.0075\n",
      "Epoch 18/25\n",
      "7/7 [==============================] - 58s 8s/step - loss: 0.0258 - accuracy: 0.9911 - val_loss: 8.4932 - val_accuracy: 0.0085\n",
      "Epoch 19/25\n",
      "7/7 [==============================] - 73s 10s/step - loss: 0.0378 - accuracy: 0.9897 - val_loss: 7.9475 - val_accuracy: 0.0160\n",
      "Epoch 20/25\n",
      "7/7 [==============================] - 70s 10s/step - loss: 0.0266 - accuracy: 0.9897 - val_loss: 11.2586 - val_accuracy: 0.0155\n",
      "Epoch 21/25\n",
      "7/7 [==============================] - 80s 11s/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 11.9611 - val_accuracy: 0.0080\n",
      "Epoch 22/25\n",
      "7/7 [==============================] - 79s 11s/step - loss: 0.0294 - accuracy: 0.9845 - val_loss: 10.4040 - val_accuracy: 0.0235\n",
      "Epoch 23/25\n",
      "7/7 [==============================] - 82s 12s/step - loss: 0.0425 - accuracy: 0.9742 - val_loss: 8.5523 - val_accuracy: 0.0160\n",
      "Epoch 24/25\n",
      "7/7 [==============================] - 74s 11s/step - loss: 0.0288 - accuracy: 0.9897 - val_loss: 9.4452 - val_accuracy: 0.0155\n",
      "Epoch 25/25\n",
      "7/7 [==============================] - 69s 10s/step - loss: 0.0342 - accuracy: 0.9866 - val_loss: 9.2778 - val_accuracy: 0.0080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1f49be7ac8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(x_train,\n",
    "                        samples_per_epoch = 250,\n",
    "                        epochs = 25,\n",
    "                        validation_data = x_test,\n",
    "                        nb_val_samples = 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"mymodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('mymodel.h5')#loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def detect(frame):\n",
    "    try:\n",
    "        img = resize(frame,(64,64))\n",
    "        img = np.expand_dims(img,axis=0)\n",
    "        if(np.max(img)>1):\n",
    "            img = img/255.0\n",
    "        prediction = model.predict(img)\n",
    "        print(prediction)\n",
    "        prediction = model.predict_classes(img)\n",
    "        print(prediction)\n",
    "    except AttributeError:\n",
    "        print(\"shape not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999169]]\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(\"C:/Users/HAI LENOVO/Desktop/remote intenship 2020/fotrst/Dataset/testset/Nofire/154.jpg\")\n",
    "data = detect(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9999651]]\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(\"C:/Users/HAI LENOVO/Desktop/remote intenship 2020/fotrst/Dataset/testset/Nofire/163.jpg\")\n",
    "data = detect(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.93131196]]\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(\"C:/Users/HAI LENOVO/Desktop/remote intenship 2020/fotrst/Dataset/testset/Nofire/175.jpg\")\n",
    "data = detect(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01184999]]\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(\"C:/Users/HAI LENOVO/Desktop/remote intenship 2020/fotrst/Dataset/testset/fires/184.jpg\")\n",
    "data = detect(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01112193]]\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(\"C:/Users/HAI LENOVO/Desktop/remote intenship 2020/fotrst/Dataset/testset/fires/197.jpg\")\n",
    "data = detect(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03169866]]\n",
      "[[0]]\n"
     ]
    }
   ],
   "source": [
    "frame=cv2.imread(\"C:/Users/HAI LENOVO/Desktop/remote intenship 2020/fotrst/Dataset/testset/fires/202.jpg\")\n",
    "data = detect(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
